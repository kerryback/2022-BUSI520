{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Day 11: Odds and Ends\n",
    "\n",
    "### BUSI 520 - Python for Business Research\n",
    "### Kerry Back, JGSB, Rice University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline \n",
    "\n",
    "- Debugging \n",
    "- Timing code \n",
    "- Parallel processing\n",
    "- GPUs\n",
    "- Geometry of ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Error messages \n",
    "\n",
    "- Find the last line of your code in the error message (before it goes into any python libraries, if it does).\n",
    "- The error is in that line or in some object that appears in that line.\n",
    "- Ask Julius/Github Copilot/ChatGPT or google if the message is not clear.\n",
    "- Inspect all of the objects in that line to see if they are what you expect them to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to inspect objects\n",
    "\n",
    "- Use type() or .shape or .head() or whatever \n",
    "- Use print statements\n",
    "- Use CTRL-SHFT-P to bring up the command palette and search for `Jupyter: Open Variables View` to see the current values of all variables.\n",
    "- Use the Data Wrangler extension to see the data in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Errors inside functions\n",
    "\n",
    "- Try to avoid them by testing code on examples before you put it into a function.\n",
    "- Take code out of the function if there's an error inside the function and test on examples.\n",
    "  - Use CTRL-[ to indent a block of code and CTRL-] to unindent it.\n",
    "- Use print statements inside the function.\n",
    "- Use the debugger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pdb debugger\n",
    "\n",
    "- Ask Github Copilot how to use the pdb debugger in Jupyter.\n",
    "- pdb.set_trace() \n",
    "- %debug magic command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timing code\n",
    "\n",
    "- Use time.time or timeit.timeit\n",
    "- Or use %%time or %%timeit magic commands in Jupyter\n",
    "- time runs once, timeit runs multiple times and averages the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def add_numbers(n):\n",
    "    return np.arange(n+1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 μs ± 10.3 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "add_numbers(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.0010008811950683594\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "add_numbers(100000)\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel processing\n",
    "\n",
    "- Use the joblib library or multiprocessing.Pool to parallelize loops.\n",
    "- Other libraries are available for more complex parallel processing.\n",
    "- Only worthwhile for tasks that take a long time to run.\n",
    "- For small tasks, parallel processing is too much overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.282323360443115\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lst = [add_numbers(n) for n in range(100000)]\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.8435566425323486\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lst = Parallel(n_jobs=-1, verbose=0)(\n",
    "    delayed(add_numbers)(n) for n in range(100000)\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GPU processing\n",
    "\n",
    "- Many cores, each slower than CPU cores.\n",
    "- Good for tasks that can be parallelized.\n",
    "- Code still runs on CPU, but tasks are sent to GPU.\n",
    "- Various libraries will automatically send tasks to the GPU and parallelize them.  \n",
    "  - Nvidia: numpy -> cupy, pandas -> cudf, scikit-learn -> cuml\n",
    "- Google Colab has free GPU access: Runtime/Select Runtime Type/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### cupy\n",
    "\n",
    "[https://colab.research.google.com/drive/1xhORH4VQr5vuaDVsvKY54JW_dIE5EMUz?usp=sharing](https://colab.research.google.com/drive/1xhORH4VQr5vuaDVsvKY54JW_dIE5EMUz?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### cudf\n",
    "\n",
    "- Can rewrite code to use cudf instead of pandas.  Almost everything is exactly the same - just use cudf.DataFrame instead of pd.DataFrame, etc.\n",
    "- Or can use magic %load_ext cudf.pandas to automatically run pandas code with cudf: \n",
    "\n",
    "[https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometry of Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS\n",
    "\n",
    "- $N$ observations, $K$ regressors, $K<N$\n",
    "- Demean $X$ and $y$, with no constant column in $X$\n",
    "- $(1/N)X'y$ is sample covariance of $y$ with $x$'s.\n",
    "- $(1/N)X'X$ is sample covariance matrix of $x$'s.\n",
    "- OLS is \n",
    "$$\\hat\\beta = (\\text{sample cov of $X$})^{-1} \\times \\text{sample cov of $X$ with $y$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why ridge is called ridge \n",
    "\n",
    "- Ridge is \n",
    "$$\\min \\frac{1}{2}(y-X\\hat\\beta)'(y-X\\hat\\beta) + \\frac{1}{2}\\lambda \\hat\\beta'\\hat\\beta$$\n",
    "- FOC is\n",
    "$$X'(y-X\\hat\\beta) - \\lambda \\hat\\beta = 0$$\n",
    "- Solution is\n",
    "$$\\hat\\beta = (X'X + \\lambda I)^{-1}X'y$$\n",
    "- So replace sample cov matrix of $X$ with $(1/N)(X'X + \\lambda I)$.\n",
    "- $\\lambda I$ adds a ridge to the diagonal of the sample cov matrix of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singular value decomposition\n",
    "\n",
    "Take the singular value decomposition $X = UDV'$.\n",
    "\n",
    "- U is $N \\times N$, D is $N \\times K$, V is $K \\times K$.\n",
    "- U and V are orthogonal matrices. \n",
    "  - Columns of U are eigenvectors of $XX'$.\n",
    "  - Columns of V are eigenvectors of $X'X$.\n",
    "- First $K$ rows of $D$ is a diagonal matrix containing the nonzero singular values of $X$.  Other rows are zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "$$\\begin{pmatrix}\n",
    "X_1 & \\cdots & X_K\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "U_1 & \\cdots & U_N\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \n",
    "d_1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "0 & d_2 & 0 & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\ \n",
    "0 & 0 & 0 & \\cdots & d_K \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix}\n",
    "V_1'\\\\\n",
    "\\vdots \\\\\n",
    "V_K'\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "- Let $\\hat U$ denote the $N \\times K$ matrix consisting of the first $K$ columns of $U$.\n",
    "- Let $\\hat D$ denote the first $K$ rows of $D$ (the nonzero rows).\n",
    "- Then, if we multiply $UDV'$ using the fact that\n",
    "$$D = \\begin{pmatrix} \\hat D \\\\ 0 \\end{pmatrix}$$\n",
    "we get\n",
    "$$X = UDV' = \\hat U \\hat D V'$$\n",
    "- $X = \\hat U\\hat D V'$ is called the compact SVD of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "- Because $X = \\hat U \\hat U D V'$ and $U$ is orthogonal, we have $X'X = V\\hat D^2V'$.  \n",
    "- This is the diagonalization of the nonsingular matrix $X'X$.\n",
    "- The $d_i^2$ are the eigenvalues of $X'X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "- Because $X = \\hat U \\hat D V'$, we have $\\hat U = XV\\hat{D}^{-1}$.\n",
    "- So the first $K$ columns of $U$ are linear combination of the columns of $X$\n",
    "- The change of variables $X \\mapsto \\hat U$ is a conversion to $K$ orthogonal variables with unit variances.\n",
    "- Change of variables $X \\mapsto \\hat U \\hat D$ is a conversion to $K$ orthogonal variables with variances equal to $d_i^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS predictions\n",
    "\n",
    "\n",
    "- We have $X'X = V\\hat D^2V'$, so $(X'X)^{-1} = V\\hat D^{-2} V'$\n",
    "- For OLS, \n",
    "$$X \\hat\\beta = XV\\hat D^{-2}V'X'y = \\hat U \\hat D \\hat D^{-2} \\hat D \\hat U'y = \\sum_{i=1}^K (\\U_i'y) U_i$$\n",
    "- This just repeats what you know: multivariate betas = univariate betas after you orthogonalize the regressors, and if the regressors have unit variances, then betas = covariances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "### Ridge predictions\n",
    "\n",
    "- We have\n",
    "$$X'X + \\lambda I = V\\hat D^2V' + \\lambda VV' = V(\\hat D^2 + \\lambda I)V'$$\n",
    "- So\n",
    "$$X \\hat\\beta = \\hat U \\hat D (\\hat D^2 + \\lambda I)^{-1} \\hat D \\hat U' y = \\sum_{i=1}^K \\frac{d_i^2}{d_i^2 + \\lambda} (U_i'y) U_i$$\n",
    "- So, the regression is as if the $U_i$ had variances equal to \n",
    "$$\\frac{d_i^2 + \\lambda}{d_i^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "### What if there are more regressors than observations?\n",
    "\n",
    "- In the singular value decomposition, $D$ has $N$ nonzero columns and $K-N$ zero columns when $K>N$.\n",
    "- And $X = UDV' = U\\hat D \\hat V'$ where $\\hat D$ is $N \\times N$ and $\\hat V$ is the first $N$ columns of $V$.  \n",
    "- But we get the same result for the predictions:\n",
    "$$X\\hat\\beta =\\sum_{i=1}^N \\frac{d_i^2}{d_i^2 + \\lambda} (U_i'y) U_i$$\n",
    "- Here, the $U_i$ are $N$ linearly independent (and orthogonal and unit variance) regressors constructed from the $K>N$ regressors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
