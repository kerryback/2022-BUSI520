{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Day 11: Odds and Ends\n",
    "\n",
    "### BUSI 520 - Python for Business Research\n",
    "### Kerry Back, JGSB, Rice University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"slideshow": {"slide_type": "slide"}},
   "source": [
    "### Outline \n",
    "\n",
    "- Debugging \n",
    "- Timing code \n",
    "- Parallel processing\n",
    "- GPUs\n",
    "- Geometry of ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Error messages \n",
    "\n",
    "- Find the last line of your code in the error message (before it goes into any python libraries, if it does).\n",
    "- The error is in that line or in some object that appears in that line.\n",
    "- Ask Julius/Github Copilot/ChatGPT or google if the message is not clear.\n",
    "- Inspect all of the objects in that line to see if they are what you expect them to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to inspect objects\n",
    "\n",
    "- Use type() or .shape or .head() or whatever \n",
    "- Use print statements\n",
    "- Use CTRL-SHFT-P to bring up the command palette and search for `Jupyter: Open Variables View` to see the current values of all variables.\n",
    "- Use the Data Wrangler extension to see the data in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Errors inside functions\n",
    "\n",
    "- Try to avoid them by testing code on examples before you put it into a function.\n",
    "- Take code out of the function if there's an error inside the function and test on examples.\n",
    "  - Use CTRL-[ to indent a block of code and CTRL-] to unindent it.\n",
    "- Use print statements inside the function.\n",
    "- Use the debugger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pdb debugger\n",
    "\n",
    "- Ask Github Copilot how to use the pdb debugger in Jupyter.\n",
    "- pdb.set_trace() \n",
    "- %debug magic command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timing code\n",
    "\n",
    "- Use time.time or timeit.timeit\n",
    "- Or use %%time or %%timeit magic commands in Jupyter\n",
    "- time runs once, timeit runs multiple times and averages the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def add_numbers(n):\n",
    "    return np.arange(n+1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 μs ± 10.3 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "add_numbers(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.0010008811950683594\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "add_numbers(100000)\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel processing\n",
    "\n",
    "- Use the joblib library or multiprocessing.Pool to parallelize loops.\n",
    "- Other libraries are available for more complex parallel processing.\n",
    "- Only worthwhile for tasks that take a long time to run.\n",
    "- For small tasks, parallel processing is too much overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.282323360443115\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lst = [add_numbers(n) for n in range(100000)]\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.8435566425323486\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lst = Parallel(n_jobs=-1, verbose=0)(\n",
    "    delayed(add_numbers)(n) for n in range(100000)\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GPU processing\n",
    "\n",
    "- Many cores, each slower than CPU cores.\n",
    "- Good for tasks that can be parallelized.\n",
    "- Code still runs on CPU, but tasks are sent to GPU.\n",
    "- Various libraries will automatically send tasks to the GPU and parallelize them.  \n",
    "  - Nvidia: numpy -> cupy, pandas -> cudf, scikit-learn -> cuml\n",
    "- Google Colab has free GPU access: Runtime/Select Runtime Type/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### cupy\n",
    "\n",
    "[https://colab.research.google.com/drive/1xhORH4VQr5vuaDVsvKY54JW_dIE5EMUz?usp=sharing](https://colab.research.google.com/drive/1xhORH4VQr5vuaDVsvKY54JW_dIE5EMUz?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### cudf\n",
    "\n",
    "- Can rewrite code to use cudf instead of pandas.  Almost everything is exactly the same - just use cudf.DataFrame instead of pd.DataFrame, etc.\n",
    "- Or can use magic %load_ext cudf.pandas to automatically run pandas code with cudf: \n",
    "\n",
    "[https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometry of Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS\n",
    "\n",
    "- Demean $X$ and $y$, with no constant column in $X$\n",
    "- $(1/N)X'y$ is sample covariance of $y$ with $x$'s.\n",
    "- $(1/N)X'X$ is sample covariance matrix of $x$'s.\n",
    "- OLS is \n",
    "$$(\\text{sample cov of $X$})^{-1} \\times \\text{sample cov of $X$ with $y$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why ridge is called ridge \n",
    "\n",
    "- Ridge is \n",
    "$$\\min \\frac{1}{2}(y-X\\beta)'(y-X\\beta) + \\lambda \\beta'\\beta$$\n",
    "- FOC is\n",
    "$$X'(y-X\\beta) - \\lambda \\beta = 0$$\n",
    "- Solution is\n",
    "$$\\beta = (X'X + \\lambda I)^{-1}X'y$$\n",
    "- So replace sample cov matrix of $X$ with $(1/N)(X'X + \\lambda I)$.\n",
    "- $\\lambda I$ adds a ridge to the diagonal of the sample cov matrix of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singular value decomposition\n",
    "\n",
    "Take the singular value decomposition $X = UDV'$.\n",
    "\n",
    "- U is $N \\times K$, D is $K \\times N$, V is $N \\times K$.\n",
    "- U and V are orthogonal matrices. \n",
    "  - Columns of U are the eigenvectors of $XX'$ corresponding to nonzero eigenvalues.\n",
    "  - Columns of V are the eigenvectors of $X'X$.\n",
    "- First $K$ columns of $D$ is a diagonal matrix containing the nonzero singular values of $X$.  Other columns are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS again \n",
    "\n",
    "- $X'X = VD^2V'$.  This is the diagonalization of the nonsingular matrix $X'X$.\n",
    "- The elements of $D^2$ are the eigenvalues of $X'X$.\n",
    "- $(X'X)^{-1} = VD^{-2}V'$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ridge again \n",
    "\n",
    "- We can write \n",
    "$$(X'X + \\lambda I) = VD^2V' + \\lambda VV' = V(D^2 + \\lambda I)V'$$\n",
    "- This implies\n",
    "$$(X'X + \\lambda I)^{-1} = V(D^2 + \\lambda I)^{-1}V'$$\n",
    "- The matrix $(D^2 + \\lambda I)^{-1}$ is diagonal with \n",
    "$$\\frac{1}{d_i^2 + \\lambda}$$ \n",
    "on the diagonal.\n",
    "- So ridge works by inflating the variances of the eigenvectors of the sample cov matrix of $X$.\n",
    "- The proportional inflation ($(d_i^2 + \\lambda)/d_i^2$) is larger for eigenvectors with smaller eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS and Ridge predictions \n",
    "\n",
    "- OLS:\n",
    "$$X\\beta = UDV'V(D^2)^{-1}V'VDU'y = UU'y = \\sum_{i=1}^K u_i(u_i'y)$$\n",
    "- Ridge:\n",
    "$$X\\beta = UDV'V(D^2 \\lambda I)^{-1}V'VDU'y$$\n",
    "$$ = UD^2(D^2 \\lambda I)^{-1}U'y = \\sum_{i=1}^K u_i\\frac{d_i^2}{d_i^2 + \\lambda}(u_i'y)$$\n",
    "- Ridge can be seen as scaling down the covariances - proportional effect is larger for lower variance eigenvectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
