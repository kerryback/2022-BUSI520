[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Kerry Back  J. Howard Creekmore Professor of Finance and Professor of Economics kerryback@gmail.com\n\n\n\nRoom 217, 2:15 – 3:45, 8/26/2024 – 10/7/2024\n\n\n\nThis course is intended for PhD students in business and economics. However, it may be appropriate for students in other programs also.\nPython is a general purpose programming language that has become especially important for machine learning and for data analysis more generally. It can be used as a substitute for MATLAB, Stata, SAS, and R and also for web scraping, natural language processing, and much more. This course provides an introduction to the language and to the libraries that are most useful for business research. The topics to be covered in the course are listed below. This is a hands-on course, and a part of each class session will be allocated to students working individually or in groups to apply and extend the class material.\nGenerative AI can write most of our code, plus we can Google (usually ending up at Stack Overflow) so memorizing syntax is not always necessary anymore. However, there are still basic things that you will want to do over and over that will be faster if you know the syntax by heart.\nIt is fine if you have zero experience with python or any other programming language. It is also fine if you are experienced with python and are taking the course only to learn about certain libraries you haven’t used before. In the former case, I will not expect you to become a proficient programmer in six weeks. My goal in that case is to introduce you to the possibilities and show you how to get started. Googling and ChatGPT can take care of the rest.\n\n\n\nThere will be weekly assignments. You are allowed to google and/or use generative AI for assistance with the assignments. There is also a project that is due at the end of October. The weekly assignments will account for half of the grade and the project for the other half (though the course is Pass/Fail, so grades aren’t extremely important). The project is to replicate Tables I, II and III from Fama and French, “The Cross-Section of Expected Stock Returns”, Journal of Finance, 1992, in python and to create at least two figures to visually represent some of the results from those tables.\n\n\n\n\nPreliminaries: VS Code, Jupyter notebooks, python scripts, libraries\nBasic python: data types, conditional statements, loops, functions, classes\nVectors and matrices: numpy\nData handling: pandas\nVisualization: matplotlib, seaborn, plotly\nScientific programming: scipy\nStatistics: statsmodels, linearmodels\nIntro to machine learning: LASSO and ridge regression\nTree models for machine learning: scikit-learn, xgboost\nNeural networks for machine learning: pytorch\nWeb scraping: beautiful soup, selenium\nReinforcement learning\n\n\n\n\nPlease install python and VS Code. If you do not currently have python on your machine, you can install from Anaconda or from python.org. Personally, I install from python.org. The differences are: (i) you get scientific packages from Anaconda but have to install them yourselves otherwise (but this is trivial and should not affect your choice), (ii) you get the conda package manager with anaconda and the pip package manager from python.org. Conda is supposed to be better at avoiding conflicts between packages, but I have not found that to be important. Pip has broader coverage of packages.\nIf you install from python.org, ON THE VERY FIRST INSTALLATION SCREEN CLICK THE BUTTON AT THE BOTTOM TO ADD PYTHON TO YOUR PATH. Or, you can add it manually later if necessary. It definitely needs to be on your path.\nIt can get complicated if you have multiple versions of python on your computer. The easiest solution is to uninstall all but one. Or, we can create local environments to have more control over packages.\nWe will primarily work with Jupyter notebooks within VS Code. There are alternate ways to run Jupyter notebooks, but VS Code is my favorite. I also use VS Code for running latex. It is also my favorite latex editor/previewer (tied with Overleaf). And it is especially convenient to be able to run python to generate things for papers and edit the paper all in the same program. So, I think it is worth learning.\nHere is a tutorial for using VS Code with python: VS Code Python Tutorial. You will need to add extensions for VS Code from the VS Code Marketplace. You will need the Python and Jupyter extensions created by Microsoft. I use the Latex Workshop extension created by James Yu. You will probably also find the Data Wrangler, Excel Viewer, and PDF Viewer extensions useful.\nThe VS Code link above also has links to python tutorials, which you could browse. There are many online python tutorials. I recommend the Sargent-Stachurski tutorials on python for economics and finance. We will roughly cover the first 9 lectures the first day of class and then the next 7 within the following two days.\nIf you install from python.org, you should install numpy, pandas, matplotlib, seaborn, scipy, statsmodels, and scikit-learn. Instructions on how to install packages are at the VS Code tutorial link. Regardless of how you install python, you should install pandas-datareader, linearmodels, wrds, beautifulsoup4, and selenium. We might also play with yfinance and cvxopt, but they are less important. When following the installation instructions, you can put multiple packages on the same line separated by spaces - e.g., pip install numpy pandas scipy\nYou can install into a virtual environment as described in the VS Code tutorial, but it is not necessary to do so. If you want to use a virtual environment, choose a folder that you will use for your work in the course and create the virtual environment in it. I sometimes use virtual environments but not always.\nYou should try out Google Colab at some point. It is a free online environment for running Jupyter notebooks that can sync with your Google Drive. A tutorial is here: Colab Tutorial.\nA more useful (but not free) resource is Julius.ai. I recommend that you get an academic subscription for at least a couple of months. It was $20 per month, though it might have gone up. And, if you are at JGSB, you can get reimbursed from your research budget. It integrates generative AI (ChatGPT and alternatives) with a python environment. You can upload data files and ask ChatGPT to write python code to do whatever you want and then see the results, revise your prompt if needed, etc. You can download and save tables or images that it creates for you. We will demonstrate it in class on Monday. There are other ways to use generative AI with python, but none of the best methods are free, because someone has to pay OpenAI or Google or whomever for access to the latest models. For example, there is a Github Copilot extension for VS Code, but then you need a subscription to Github Copilot.\nAnother useful thing is github. At this point, it will be useful to you mostly because many many people put their code there and you may want to download some. You can learn to use git from the command line or a GUI, or you can just learn to click a button. You should download the Sargent-Stachurski notebooks. We’ll also look at some of Kevin Sheppard’s stuff (Sheppard is an econometrician at Oxford). Open Source Asset Pricing is another useful resource, though all of their code is in R.\n\n\n\nThe Rice University honor code applies to all work in this course. Each student must do his or her own assignments, but it is allowed and in fact encouraged for students to seek advice from each other.\n\n\n\nAny student with a documented disability requiring accommodations in this course is encouraged to contact me outside of class. All discussions will remain confidential. Any adjustments or accommodations regarding assignments or the final exam must be made in advance. Students with disabilities should also contact Disability Support Services in the Allen Center."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "",
    "section": "",
    "text": "1. Intro to Python\n2. Numpy and Pandas\n3. More Pandas\n4. Visualizaton\n5. Scientific Programming\n6. Machine Learning"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "",
    "section": "",
    "text": "Create a function that takes the lengths of two sides of a right triangle as inputs and returns the length of the hypotenuse.\n\nCreate a list of names. Using list enumeration, print the names in the form\n\n    1. Adam\n    2. Bob\n    3. ...\n\nCreate a function that takes a list of strings as an input and prints the list as in part (a).\nCreate a function that takes a list of strings as its input and returns a dictionary with integers 1, 2, … as keys and the strings as values.\n\nCreate a list of numbers from 1 to 10.\n\nWrite a loop to print only even numbers from the list.\nWrite another loop to calculate and print the factorial of each number in the list.\n\nWrite a loop to halve a given number until the result is less than 1.0e-6.\nCreate a function is_palindrome to check if a string is a palindrome (reads the same forwards as backwards – e.g., ‘radar’ is a palindrome). The function should return True if the input is a palindrome and False otherwise.\nWrite a script (.py file) that prompts the user to input\n\ntitle\nauthor\njournal\nvolume\npages\nyear\nkeyword\npathname of a .bib file\n\nThe function should then append a bibtex entry to the end of the .bib file formatted as follows, where the items within braces are the user’s inputs.\n\n    @article{keyword,\n    title={title},\n    author={author names},\n    journal={journal name},\n    volume={volume number},\n    pages={pages},\n    year={year},\n    }"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "",
    "section": "",
    "text": "1. Introduction to Python\n2. Introduction to NumPy\n3. Introduction to Pandas\n4. Additional Pandas\n5. WRDS\n6. Visualization\n7. Scientific Programming\n8. Dynamic Programming\n9. SymPy\n10. Statistics\n11. Introduction to Machine Learning\n12. More Machine Learning\n13. Preprocessing\n14. Neural Networks\n15. Web Scraping"
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "",
    "section": "",
    "text": "Creating Arrays:\n\nCreate a one-dimensional array of integers from 0 to 9.\nCreate a two-dimensional array of zeros with shape (5, 5).\nCreate a three-dimensional array of ones with shape (2, 3, 4).\n\nManipulating Arrays:\n\nReshape the above two-dimensional array to a one-dimensional array.\nStack two arrays horizontally and vertically.\nSplit a given array into multiple sub-arrays.\nFlatten a multi-dimensional array.\nExpand the dimensions of a one-dimensional array.\n\nArray Indexing:\n\nExtract the third and fifth elements from a one-dimensional array.\nExtract a 2x2 sub-matrix from a given two-dimensional array.\nUse boolean indexing to extract even numbers from an array.\n\nArithmetic Operations:\n\nPerform element-wise addition, subtraction, multiplication, and division on two given arrays.\nMultiply a 2x3 matrix with a 1x3 matrix using broadcasting.\n\nAggregation Functions:\n\nCalculate the sum, mean, standard deviation, and variance of a one-dimensional array.\nFind the minimum and maximum values in a one-dimensional array.\nRepeat (a) and (b) along a single axis of a two-dimensional array.\n\nLinear Algebra:\n\nTranspose a matrix\nMultiply two matrices.\nCompute the dot product of two vectors.\nCalculate the determinant of a matrix.\nCompute the eigenvalues and eigenvectors of a matrix.\nSolve a system of linear equations using NumPy.\n\nSimulation:\n\nSimulate 100 steps of a random walk with standard normal innovations.\nGenerate 1,000 simulations of the random walk from part (a). Compute the mean, median, and standard deviation of the terminal value across the 1,000 simulations.\n\n\n\n\n\nBasics of pandas Series and DataFrames\n\nCreate a series from a list of integers.\nExtract values at specific indices from the Series.\nChange the index of the series to alphabetical letters.\nCreate a dataFrame from a dictionary of lists.\nExtract specific columns from the dataFrame.\nAdd a new column to the dataFrame.\nCreate a dataframe filled with random numbers.\n\nBasic DataFrame Operations:\n\nCalculate the summary statistics for a DataFrame column.\nSort the dataFrame based on a specific column.\nFilter rows based on certain criteria.\nReplace specific values in a DataFrame.\nRename columns.\nMap values in a column to other values using a dictionary.\n\nMissing values:\n\n\nFind all missing values in a DataFrame. b Fill missing values with zeros.\nFill missing values in a column with the column’s mean value.\nDrop rows with missing data.\nFind duplicate rows.\nDrop all but the last row in each set of duplicate rows.\n\n\nFiltering and Aggregation:\n\n\nUsing the ‘tips’ dataset, filter the rows where the total bill is greater than $10.\nCreate a new column in the ‘tips’ dataset called ‘bill_per_person’ which is the total bill divided by the size of the party.\nGroup by the ‘day’ column and compute the average total bill for each day."
  },
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "",
    "section": "",
    "text": "Assignment 1\n\nJupyter Notebook\nPython Script"
  },
  {
    "objectID": "slides.html#slide-decks-busi-520-python-for-business-research",
    "href": "slides.html#slide-decks-busi-520-python-for-business-research",
    "title": "",
    "section": "",
    "text": "1. Introduction to Python\n2. Introduction to NumPy\n3. Introduction to Pandas\n4. Additional Pandas\n5. WRDS\n6. Visualization\n7. Scientific Programming\n8. Dynamic Programming\n9. SymPy\n10. Statistics\n11. Introduction to Machine Learning\n12. More Machine Learning\n13. Preprocessing\n14. Neural Networks\n15. Web Scraping"
  },
  {
    "objectID": "index.html#python-for-business-research-rice-university-fall-2023",
    "href": "index.html#python-for-business-research-rice-university-fall-2023",
    "title": "",
    "section": "",
    "text": "Kerry Back  J. Howard Creekmore Professor of Finance and Professor of Economics kerryback@gmail.com\n\n\n\nRoom 316, 10:15 – 11:45, 8/21/2023 – 10/2/2023\n\n\n\nThis course is intended for PhD students in business and economics. However, it may be appropriate for students in other programs also.\nPython is a general purpose programming language that has become especially important for machine learning and for data analysis more generally. It can be used as a substitute for MATLAB, Stata, SAS, and R and also for web scraping, natural language processing, and much more. This course provides an introduction to the language and to the libraries that are most useful for business research. The topics to be covered in the course are listed below. This is a hands-on course, and a part of each class session will be allocated to students working individually or in groups to apply and extend the class material.\nChatGPT makes it much easier to use python. Throughout the course, we will generate python code by using ChatGPT-4 either at the OpenAI website (for this, I highly recommend a Plus subscription) or via an extension to VS Code.\nIt is fine if you have zero experience with python or any other programming language. It is also fine if you are experienced with python and are taking the course only to learn about certain libraries you haven’t used before. In the former case, I will not expect you to become a proficient programmer in six weeks. My goal in that case is to introduce you to the possibilities and show you how to get started. Googling and ChatGPT can take care of the rest.\n\n\n\nThere will be weekly assignments. You are allowed to google and/or to use ChatGPT for assistance with the assignments. There will not be an exam.\n\n\n\nThis is a tentative schedule. I think it is a feasible schedule even for students with zero prior programming experience. However, it may be modified based on student interests and experience.\n\nPreliminaries: libraries, IDEs, environments, git\nBasic python: data types, conditional statements, loops, functions, classes\nVectors and matrices: numpy\nData handling: pandas\nVisualization: matplotlib, seaborn, plotly\nScientific programming: scipy\nStatistics: statsmodels, linearmodels\nTree models for machine learning: scikit-learn, xgboost\nNeural networks for machine learning: pytorch\nNeural networks for solving games, dynamic programming, and differential equations\nReinforcement learning\nWeb scraping: beautiful soup, selenium"
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "",
    "section": "",
    "text": "Read the datasets announcements.csv and crsp.csv files located in the notebooks repo into dataframes. Each row of announcements.csv is a (stock, quarter) pair. Each row of crsp.csv is a (stock, month) pair. Complete the following. Upload a zip file containing (i) your code, (ii) a text file or Word doc containing your answers to 1, 2, 9, 10, 11, 12, and 15, and (iii) three .csv files as specified in 8, 11, and 14.\n\nHow many stock-months (rows) are there in the crsp dataframe? How many stock-quarters (rows) are there in announcements.csv?\nHow many unique permnos are there in the announcements dataframe? Hint: there is a “unique” method. Use “len” also.\nCreate a “quarter” column in the announcements dataframe based on the fiscal_period column.\nCreate a “quarter” column in the crsp dataframe based on the date column.\nExtract the last day of each quarter for each permno in the crsp dataframe. Hint: use groupby and .last().\nChange the name of the ‘date’ column in the announcements dataframe to ‘ea_date’. This is the date of the firm’s quarterly earnings announcement. Hint: pass a dictionary as columns = {‘old name’: ‘new name’} to the rename method.\nMerge the reduced crsp dataframe with the announcement dataframe, matching on [‘permno’, ‘quarter’]. Hint: permno and quarter will form the index of the reduced crsp dataframe after grouping. You will need to reset the index or use left_on=… and right_index=True, or right_on=… and left_index=True in the merge.\nFilter the merged dataframe to keep only rows satisfying price>=5, me>=50000, and shrcd in [10, 11]. Save this as a csv file with the name merged.csv and submit on Canvas. Use the filtered dataframe to answer all remaining questions.\nHow many stock-quarters are there in the filtered dataframe and how many unique permnos?\nWhich day of the week is the most popular day for earnings announcements? What fraction of earnings announcements occur on this day? Hint: the weekday method of a datetime object returns 0 for Monday, 1 for Tuesday, etc.\nFor each permno, find the most popular day of the week for earnings announcements. For each permno, calculate the fraction of the announcements that are made on that day. Save this as a csv file with the name days.csv and submit on Canvas. What is the mean of this fraction across permnos?\nCut the dataframe into ‘above median’ and ‘below median’ based on the absolute value of date_diff. What is the mean of the fraction in the previous queston across permnos within each of the two groups?\nFor each permno, calculate the fraction of zeros for date_diff.\nFilter the dataframe further to include only stock-quarters for which\n\nthe fraction of zeros for date_diff is less than 0.5\nthe fraction of announcements on the permno’s most popular day of the week is less than 0.9.\n\n\nSave this as a csv file with the name filtered.csv and submit on Canvas.\n\nHow many stock-quarters are in the newly filtered dataframe? How many unique permnos?"
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "",
    "section": "",
    "text": "Submit a Jupyter notebook. Answer the “what do you learn” questions in markdown cells.\n\nCreate a figure or figures to show the different distributions of wages for white males, white females, nonwhite males, and nonwhite females in the WAGES1 dataset. What do you learn from the figure.\nCreate a figure or figures to show how wage depends on education for white males, white females, nonwhite males, and nonwhite females in the WAGES1 dataset. Change the 0-1 dummy variables to more informative names so the legend will be easier to interpret. What do you learn from the figure?\nCreate a pairplot of educ and wage. Use hue=“female.” Change the dummy variable to more informative names so the legend will be easier to interpret. Add regression lines to the scatterplot in a different color than the points. Create it as a lower diagonal matrix to reduce the clutter (i.e., only one scatter plot). Put educ on the x-axis of the scatter plot. What do you learn from the figure?\nFor 3d plotting, we used code like the following:\n\na = np.linspace(0, 10, 11)\nb = np.linspace(10, 20, 11)\nA, B = np.meshgrid(a, b)\nLook at A and B and explain what they are. Define\nC = A + B\nCreate a filled contour plot with three labeled contour lines at the values C=15, C=20, and C=25.\n\nThe file option_sims.csv contains simulations from a model of market maker profits and stock and option order imbalances. Produce a bivariate density plot of the stock and option order imbalances. What do you learn from the figure?\nBin the stock and option order imbalances into a 100 x 100 grid and compute the average market maker profits in each cell. Use a heatmap to show the average market maker profits as a function of the stock and option order imbalances. What do you learn from the figure?\nCreate a stacked bar chart to show the different distributions of tips for males and females in the seaborn tips dataset. What do you learn from the figure?"
  },
  {
    "objectID": "assignment4.html#assignment-4-busi-520-python-for-business-research-jones-graduate-school-of-business-rice-university",
    "href": "assignment4.html#assignment-4-busi-520-python-for-business-research-jones-graduate-school-of-business-rice-university",
    "title": "",
    "section": "",
    "text": "Submit a Jupyter notebook. Answer the “what do you learn” questions in markdown cells.\n\nCreate a stacked bar chart to show the different distributions of tips for males and females in the seaborn tips dataset. What do you learn from the figure?\nCreate a figure or figures to show the different distributions of wages for white males, white females, nonwhite males, and nonwhite females in the WAGES1 dataset. What do you learn from the figure.\nCreate a figure or figures to show how wage depends on education for white males, white females, nonwhite males, and nonwhite females in the WAGES1 dataset. Change the 0-1 dummy variables to more informative names so the legend will be easier to interpret. What do you learn from the figure?\nCreate a pairplot of educ and wage. Use hue=“female.” Change the dummy variable to more informative names so the legend will be easier to interpret. Add regression lines to the scatterplot in a different color than the points. Create it as a lower diagonal matrix to reduce the clutter (i.e., only one scatter plot). Put educ on the x-axis of the scatter plot. What do you learn from the figure?\nFor 3d plotting, we used code like the following:\n\na = np.linspace(0, 1, 11)\nb = np.linspace(10, 20, 11)\nA, B = np.meshgrid(a, b)\nLook at A and B and explain what they are. Define\nC = A + B\nCreate a filled contour plot with three labeled contour lines at the values C=15, C=20, and C=25.\n\nThe file option_sims.csv contains simulations from a model of market maker profits and stock and option order imbalances. Produce a bivariate density plot of the stock and option order imbalances. What do you learn from the figure?\nBin the stock and option order imbalances into a 100 x 100 grid and compute the average market maker profits in each cell. Use a heatmap to show the average market maker profits as a function of the stock and option order imbalances. What do you learn from the figure?"
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "",
    "section": "",
    "text": "Submit a Jupyter notebook.\n\nCreate a function that takes a 2x2 game as an input and returns a list of the pure strategy Nash equilibria. If there are no pure strategy equilibria, then it should return an empty list. It should accept a game input as a 2x2 array of tuples, the first element of the tuple being the utility of the row player and the second element being the utility of the column player. Here is an example of a game that it should accept as its input:\n\ngame = [\n    [(5, 0), (5, 5)],\n    [(5, 2), (0, 0)]\n]\nIf you prefer some other format for representing the game, then the first part of your function should transform the 2x2 array of tuples into your preferred form.\n\nThe following function accepts as its input a 2x2 array of tuples and returns a list. Move the code outside the function, create an example 2x2 array and execute the code line by line. Display in your notebook the object created by each line and explain what it is and what operation was performed to create it.\n\ndef nash(game):\n\n    g = pd.DataFrame(\n        game, \n        index = [\"T\", \"B\"],\n        columns = [\"L\", \"R\"]\n    )\n    g = g.unstack()\n    g.index.names = [\"col\", \"row\"]\n    \n    g = pd.concat(\n        (\n            g.map(lambda x: x[0]), \n            g.map(lambda x: x[1])\n        ), \n        axis=1\n    )\n    g.columns = [\"u1\", \"u2\"]\n    g.index = g.index.swaplevel()\n\n    row_max = g.groupby(\"col\").apply(\n        lambda x: x[x.u1 == x.u1.max()].index.values\n    )\n    row_max = [x for arr in row_max for x in arr]\n\n    col_max = g.groupby(\"row\").apply(\n        lambda x: x[x.u2 == x.u2.max()].index.values\n    )\n    col_max = [x for arr in col_max for x in arr]\n\n    return list(set(col_max) & set(row_max))\n\nThe knapsack problem is as follows. There are \\(n\\) objects that you might put in your knapsack (backpack). Each has a weight \\(w_i\\) and a value \\(u_i\\). Your knapsack can only hold a total weight of \\(W\\). Among the combinations of objects that have a combined weight no more than \\(W\\), you want to choose the combination that has the maximum total value. Denote your decision about whether to include the \\(i\\)-th object as \\(a_i \\in \\{0, 1\\}\\), with \\(a_i=1\\) meaning put it in the knapsack. So, the problem is to choose the \\(a_i\\) to maximize \\(\\sum_{i=1}^n a_iu_i\\) subject to \\(\\sum_{i=1}^n a_iw_i \\le W\\). We can write this as a nonstationary finite dynamic programming problem by supposing that we first consider object 1 (at “time 1”) then move on to consider object 2 (at “time 2”), etc. Denote the weight in the knapsack prior to making the \\(i\\)-th decision by \\(x_i\\). Denote the total value of the objects in the knapsack prior to making the \\(i\\)-th decison by \\(y_i\\). The pair \\((x_i, y_i)\\) serves as the state vector for the problem. Write code to (1) calculate the value function \\(V_n(x, y)\\) before making the \\(n\\)-th decison by maximizing the ending value \\(y + au_n\\) subject to the constraints imposed by \\(x\\), and (2) use the recursion \\[V_{i}(x, y) = \\max_{a \\in \\{0, 1\\} } V_{i+1}(x+aw_i, y+au_i) \\quad \\text{subject to} \\quad x+aw_i \\le W\\] to compute \\(V_1(0, 0)\\), which is the maximum total value the knapsack can hold."
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "",
    "section": "",
    "text": "The UnivariateSpline function from scipy fits a cubic spline to data, as we’ve seen before. The following code wraps the function into a scikit-learn Estimator, which can be used like the other estimators we’ve studied. For example, you can execute\n\n  model = Spline(x=10)\n  model.fit(...)\n  import numpy as np\n  from scipy.interpolate import UnivariateSpline\n  from sklearn.base import BaseEstimator\n  from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n  class Spline(BaseEstimator):\n\n    def __init__(self, s=1):\n        self.s = s\n\n    def fit(self, X, y):\n         \n        # Check that X and y have correct shape\n        X, y = check_X_y(X, y)\n\n        # store the fitted estimator\n        self.X_ = X\n        self.y_ = y\n        self.spline = UnivariateSpline(X, y, s=self.s)\n    \n        return self\n\n    def predict(self, X):\n\n        # Check if fit has been called\n        check_is_fitted(self)\n\n        # Input validation\n        X = check_array(X)\n    \n        return self.spline(X)\nRun train-test-split in our “noisy sine curve example” and then run GridSearchCV on Spline on the training data to find the best value of s among (1, 10, 100, 1000, 10000). [To learn more about creating Estimators, see https://scikit-learn.org/stable/developers/develop.html.]\n\nThe following generates data in which the target takes the high value (2) in the northeast and southwest quadrants, the low value (0) in the other quadrants, except that it takes the middle value (1) around the origin.\n\n    np.random.seed(0)\n    X = pd.DataFrame(\n        np.random.normal(size=(1000, 2))\n    )\n    y = X[0]*X[1]\n    y = 1*(y>-0.3) + 1*(y>0.3)\n\nRun the following code from the Visualization notebook to see the data. The horizontal and vertical axis labels will be the percentiles of X[0] and X[1] from low to high.\n\n    from scipy.stats import binned_statistic_2d\n    import seaborn as sns\n\n    statistic, x_edge, y_edge, binnumber = binned_statistic_2d(\n        X[0], X[1], y,\n        statistic='mean', \n        bins=[100, 100]\n    )\n\n    sns.heatmap(\n        statistic.T, \n        cmap='coolwarm',\n        cbar=True\n    )\n    plt.gca().invert_yaxis()\n    plt.show()\n\nRun GridSearchCV on RandomForestClassifier for max_depths in (4, 6, 8, 10, 12, 16). Report the best max_depth and the score on the test data.\n\n\nRun train-test-split on scikit-learn’s wine dataset. Create pipelines with StandardScaler and (a) LogisticRegression with an \\(\\ell^2\\) penalty, (b) RandomForestClassifier, and (c) MLPClassifier on scikit-learn’s wine dataset. Run GridSearchCV on the pipeline in each case to get some idea of the best hyperparameters. Report (i) the best hyperparameters, (ii) the fraction correct on the test data, and (iii) the confusion matrix for the test data. For MLPClassifier, use\n\nmodel = MLPClassifier(solver=\"adam\")"
  },
  {
    "objectID": "index.html#python-for-business-research-rice-university-fall-2024",
    "href": "index.html#python-for-business-research-rice-university-fall-2024",
    "title": "",
    "section": "",
    "text": "Kerry Back  J. Howard Creekmore Professor of Finance and Professor of Economics kerryback@gmail.com\n\n\n\nRoom 217, 2:15 – 3:45, 8/26/2024 – 10/7/2024\n\n\n\nThis course is intended for PhD students in business and economics. However, it may be appropriate for students in other programs also.\nPython is a general purpose programming language that has become especially important for machine learning and for data analysis more generally. It can be used as a substitute for MATLAB, Stata, SAS, and R and also for web scraping, natural language processing, and much more. This course provides an introduction to the language and to the libraries that are most useful for business research. The topics to be covered in the course are listed below. This is a hands-on course, and a part of each class session will be allocated to students working individually or in groups to apply and extend the class material.\nGenerative AI can write most of our code, plus we can Google (usually ending up at Stack Overflow) so memorizing syntax is not always necessary anymore. However, there are still basic things that you will want to do over and over that will be faster if you know the syntax by heart.\nIt is fine if you have zero experience with python or any other programming language. It is also fine if you are experienced with python and are taking the course only to learn about certain libraries you haven’t used before. In the former case, I will not expect you to become a proficient programmer in six weeks. My goal in that case is to introduce you to the possibilities and show you how to get started. Googling and ChatGPT can take care of the rest.\n\n\n\nThere will be weekly assignments. You are allowed to google and/or use generative AI for assistance with the assignments. There is also a project that is due at the end of October. The weekly assignments will account for half of the grade and the project for the other half (though the course is Pass/Fail, so grades aren’t extremely important). The project is to replicate Tables I, II and III from Fama and French, “The Cross-Section of Expected Stock Returns”, Journal of Finance, 1992, in python and to create at least two figures to visually represent some of the results from those tables.\n\n\n\n\nPreliminaries: VS Code, Jupyter notebooks, python scripts, libraries\nBasic python: data types, conditional statements, loops, functions, classes\nVectors and matrices: numpy\nData handling: pandas\nVisualization: matplotlib, seaborn, plotly\nScientific programming: scipy\nStatistics: statsmodels, linearmodels\nIntro to machine learning: LASSO and ridge regression\nTree models for machine learning: scikit-learn, xgboost\nNeural networks for machine learning: pytorch\nWeb scraping: beautiful soup, selenium\nReinforcement learning\n\n\n\n\nPlease install python and VS Code. If you do not currently have python on your machine, you can install from Anaconda or from python.org. Personally, I install from python.org. The differences are: (i) you get scientific packages from Anaconda but have to install them yourselves otherwise (but this is trivial and should not affect your choice), (ii) you get the conda package manager with anaconda and the pip package manager from python.org. Conda is supposed to be better at avoiding conflicts between packages, but I have not found that to be important. Pip has broader coverage of packages.\nIf you install from python.org, ON THE VERY FIRST INSTALLATION SCREEN CLICK THE BUTTON AT THE BOTTOM TO ADD PYTHON TO YOUR PATH. Or, you can add it manually later if necessary. It definitely needs to be on your path.\nIt can get complicated if you have multiple versions of python on your computer. The easiest solution is to uninstall all but one. Or, we can create local environments to have more control over packages.\nWe will primarily work with Jupyter notebooks within VS Code. There are alternate ways to run Jupyter notebooks, but VS Code is my favorite. I also use VS Code for running latex. It is also my favorite latex editor/previewer (tied with Overleaf). And it is especially convenient to be able to run python to generate things for papers and edit the paper all in the same program. So, I think it is worth learning.\nHere is a tutorial for using VS Code with python: VS Code Python Tutorial. You will need to add extensions for VS Code from the VS Code Marketplace. You will need the Python and Jupyter extensions created by Microsoft. I use the Latex Workshop extension created by James Yu. You will probably also find the Data Wrangler, Excel Viewer, and PDF Viewer extensions useful.\nThe VS Code link above also has links to python tutorials, which you could browse. There are many online python tutorials. I recommend the Sargent-Stachurski tutorials on python for economics and finance. We will roughly cover the first 9 lectures the first day of class and then the next 7 within the following two days.\nIf you install from python.org, you should install numpy, pandas, matplotlib, seaborn, scipy, statsmodels, and scikit-learn. Instructions on how to install packages are at the VS Code tutorial link. Regardless of how you install python, you should install pandas-datareader, linearmodels, wrds, beautifulsoup4, and selenium. We might also play with yfinance and cvxopt, but they are less important. When following the installation instructions, you can put multiple packages on the same line separated by spaces - e.g., pip install numpy pandas scipy\nYou can install into a virtual environment as described in the VS Code tutorial, but it is not necessary to do so. If you want to use a virtual environment, choose a folder that you will use for your work in the course and create the virtual environment in it. I sometimes use virtual environments but not always.\nYou should try out Google Colab at some point. It is a free online environment for running Jupyter notebooks that can sync with your Google Drive. A tutorial is here: Colab Tutorial.\nA more useful (but not free) resource is Julius.ai. I recommend that you get an academic subscription for at least a couple of months. It was $20 per month, though it might have gone up. And, if you are at JGSB, you can get reimbursed from your research budget. It integrates generative AI (ChatGPT and alternatives) with a python environment. You can upload data files and ask ChatGPT to write python code to do whatever you want and then see the results, revise your prompt if needed, etc. You can download and save tables or images that it creates for you. We will demonstrate it in class on Monday. There are other ways to use generative AI with python, but none of the best methods are free, because someone has to pay OpenAI or Google or whomever for access to the latest models. For example, there is a Github Copilot extension for VS Code, but then you need a subscription to Github Copilot.\nAnother useful thing is github. At this point, it will be useful to you mostly because many many people put their code there and you may want to download some. You can learn to use git from the command line or a GUI, or you can just learn to click a button. You should download the Sargent-Stachurski notebooks. We’ll also look at some of Kevin Sheppard’s stuff (Sheppard is an econometrician at Oxford). Open Source Asset Pricing is another useful resource, though all of their code is in R.\n\n\n\nThe Rice University honor code applies to all work in this course. Each student must do his or her own assignments, but it is allowed and in fact encouraged for students to seek advice from each other.\n\n\n\nAny student with a documented disability requiring accommodations in this course is encouraged to contact me outside of class. All discussions will remain confidential. Any adjustments or accommodations regarding assignments or the final exam must be made in advance. Students with disabilities should also contact Disability Support Services in the Allen Center."
  },
  {
    "objectID": "index.html#course-preliminaries",
    "href": "index.html#course-preliminaries",
    "title": "",
    "section": "Course Preliminaries",
    "text": "Course Preliminaries\nPlease install python and VS Code. If you do not currently have python on your machine, you can install from Anaconda (https://www.anaconda.com/download) or from python.org (https://www.python.org/). Personally, I install from python.org. The differences are: (i) you get scientific packages from Anaconda but have to install them yourselves otherwise (but this is trivial and should not affect your choice), (ii) you get the conda package manager with anaconda and the pip package manager from python.org. Conda is supposed to be better at avoiding conflicts between packages, but I have not found that to be important. Pip has broader coverage of packages.\nIf you install from python.org, ON THE VERY FIRST INSTALLATION SCREEN CLICK THE BUTTON AT THE BOTTOM TO ADD PYTHON TO YOUR PATH. Or, you can add it manually later if necessary. It definitely needs to be on your path.\nIt can get complicated if you have multiple versions of python on your computer. The easiest solution is to uninstall all but one. Or, we can create local environments to have more control over packages.\nWe will primarily work with Jupyter notebooks within VS Code. There are alternate ways to run Jupyter notebooks, but VS Code is my favorite. I also use VS Code for running latex. It is also my favorite latex editor/previewer (tied with Overleaf). And it is especially convenient to be able to run python to generate things for papers and edit the paper all in the same program. So, I think it is worth learning.\nHere is a tutorial for using VS Code with python: https://code.visualstudio.com/docs/python/python-tutorial. You will need to add extensions for VS Code from here: https://marketplace.visualstudio.com/vscode. You will need the Python and Jupyter extensions created by Microsoft. I use the Latex Workshop extension created by James Yu. You will probably also find the Data Wrangler, Excel Viewer, and PDF Viewer extensions useful.\nThe VS Code link above also has links to python tutorials, which you could browse. There are many online python tutorials. I recommend the Sargent-Stachurski tutorials on python for economics and finance here: https://python-programming.quantecon.org/intro.html. We will roughly cover the first 9 lectures the first day of class and then the next 7 within the following two days.\nIf you install from python.org, you should install numpy, pandas, matplotlib, seaborn, scipy, statsmodels, and scikit-learn. Instructions on how to install packages are at the VS Code tutorial link. Regardless of how you install python, you should install pandas-datareader, linearmodels, and wrds. We might also play with yfinance and cvxopt, but they are less important. When following the installation instructions, you can put multiple packages on the same line separated by spaces - i.e., install numpy pandas scipy\nYou can install into a virtual environment as described in the VS Code tutorial, but it is not necessary to do so. If you want to use a virtual environment, choose a folder that you will use for your work in the course and create the virtual environment in it. I sometimes use virtual environments but not always.\nYou should try out Google Colab at some point. It is a free online environment for running Jupyter notebooks that can sync with your Google Drive. A tutorial is here: https://colab.research.google.com/drive/16pBJQePbqkz3QFV54L4NIkOn1kwpuRrj.\nA more useful (but not free) resource is Julius.ai (https://julius.ai/). I recommend that you get an academic subscription for at least a couple of months. It was $20 per month, though it might have gone up. And, if you are at JGSB, you can get reimbursed from your research budget. It integrates generative AI (ChatGPT and alternatives) with a python environment. You can upload data files and ask ChatGPT to write python code to do whatever you want and then see the results, revise your prompt if needed, etc. You can download and save tables or images that it creates for you. We will demonstrate it in class on Monday. There are other ways to use generative AI with python, but none of the best methods are free, because someone has to pay OpenAI or Google or whomever for access to the latest models. For example, there is a Github Copilot extension for VS Code, but then you need a subscription to Github Copilot.\nAnother useful thing is github. At this point, it will be useful to you mostly because many many people put their code there and you may want to download some. You can learn to use git from the command line or a GUI, or you can just learn to click a button: https://stackoverflow.com/questions/6466945/fastest-way-to-download-a-github-repository. The Sargent-Stachurski stuff is here: https://github.com/QuantEcon/QuantEcon.py. We’ll also look at some of Kevin Sheppard’s stuff: https://github.com/bashtage (Sheppard is an econometrician at Oxford). Open Source Asset Pricing is another useful resource, though all of their code is in R: https://github.com/OpenSourceAP/CrossSection/."
  },
  {
    "objectID": "index.html#honor-code",
    "href": "index.html#honor-code",
    "title": "",
    "section": "Honor Code",
    "text": "Honor Code\nThe Rice University honor code applies to all work in this course. Each student must do his or her own assignments, but it is allowed and in fact encouraged for students to seek advice from each other."
  },
  {
    "objectID": "index.html#disability-accommodations",
    "href": "index.html#disability-accommodations",
    "title": "",
    "section": "Disability Accommodations",
    "text": "Disability Accommodations\nAny student with a documented disability requiring accommodations in this course is encouraged to contact me outside of class. All discussions will remain confidential. Any adjustments or accommodations regarding assignments or the final exam must be made in advance. Students with disabilities should also contact Disability Support Services in the Allen Center."
  },
  {
    "objectID": "assignments.html#assignments-busi-520-python-for-business-research",
    "href": "assignments.html#assignments-busi-520-python-for-business-research",
    "title": "",
    "section": "",
    "text": "1. Intro to Python\n2. Numpy and Pandas\n3. More Pandas\n4. Visualizaton\n5. Scientific Programming\n6. Machine Learning"
  }
]